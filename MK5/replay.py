import gym
import gym_super_mario_bros
from gym.wrappers import FrameStack, GrayScaleObservation
from nes_py.wrappers import JoypadSpace
from pathlib import Path
from agent import Mario
from wrappers import ResizeObservation, SkipFrame

ACTION_SPACE = [
    ["right"],           # 0: ê±·ê¸°
    ["right", "A"],      # 1: ì í”„í•˜ë©° ê±·ê¸°
    ["right", "B"],      # 2: ë‹¬ë¦¬ê¸°
    ["right", "A", "B"], # 3: ë‹¬ë¦¬ë©° ì í”„
]

# 1. í™˜ê²½ ìƒì„± (í•™ìŠµ ë•Œì™€ ë˜‘ê°™ì´ ë§ì¶°ì•¼ í•¨!)
env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')
env = JoypadSpace(env, ACTION_SPACE)
env = SkipFrame(env, skip=4)
env = GrayScaleObservation(env, keep_dim=False)
env = ResizeObservation(env, shape=84)

# â­â­â­ [í•µì‹¬ ìˆ˜ì •] TransformObservation ì‚­ì œ! â­â­â­
# env = TransformObservation(env, f=lambda x: x / 255.)  <-- ì´ê±° ì§€ì›Œì•¼ ë§ˆë¦¬ì˜¤ê°€ ì•ì„ ë´…ë‹ˆë‹¤.

env = FrameStack(env, num_stack=4)
env.reset()

# 2. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
# ê²½ë¡œê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš” (íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€)
checkpoint_path = Path('/home/jwg/MadMario/MK5/checkpoints/2025-12-09T07-23-50/best_model.chkpt')

# ì €ì¥í•  í•„ìš” ì—†ìœ¼ë‹ˆ save_dirì€ ì•„ë¬´ê±°ë‚˜
save_dir = Path('checkpoints') 

mario = Mario(
    state_dim=(4, 84, 84), 
    action_dim=env.action_space.n, 
    save_dir=save_dir, 
    checkpoint=checkpoint_path
)

# â­â­â­ [í•µì‹¬ ìˆ˜ì •] íƒí—˜ë¥  0% ì„¤ì • (ëœë¤ í–‰ë™ ê¸ˆì§€) â­â­â­
mario.exploration_rate = 0.0
# í•™ìŠµ ëª¨ë“œê°€ ì•„ë‹ˆë¯€ë¡œ burninë„ í•´ì œ
mario.burnin = 0 

print("ğŸ® Test Drive Start!")

episodes = 5  # 5íŒë§Œ êµ¬ê²½

for e in range(episodes):
    state = env.reset()
    total_reward = 0
    
    while True:
        # í™”ë©´ ì¶œë ¥ (ì†ë„ê°€ ë„ˆë¬´ ë¹ ë¥´ë©´ time.sleepì„ importí•´ì„œ ì¡°ì ˆ ê°€ëŠ¥)
        env.render()

        # í–‰ë™ ê²°ì • (íƒí—˜ ì—†ì´ 100% ì‹¤ë ¥ìœ¼ë¡œ)
        action = mario.act(state)

        next_state, reward, done, info = env.step(action)
        
        # í…ŒìŠ¤íŠ¸ ë•ŒëŠ” cache(ì €ì¥)ë‚˜ learn(í•™ìŠµ)ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # mario.cache(...) -> ì‚­ì œ
        
        total_reward += reward
        state = next_state

        if done or info['flag_get']:
            break

    print(f"Episode {e+1} - Total Reward: {total_reward}")

env.close()