import random, datetime
from pathlib import Path
import torch

from metrics import MetricLogger
from agent import Mario
from wrappers import create_mario_env

# 1. í™˜ê²½ ìƒì„±
env = create_mario_env(skip_frame=4)

# 2. ìƒˆë¡œìš´ ì €ì¥ ê²½ë¡œ ìƒì„± (ì´ì–´í•˜ê¸° ê¸°ë¡ì„ ë”°ë¡œ ì €ì¥)
# ê¸°ì¡´ í´ë”ì— ì„ì´ì§€ ì•Šê²Œ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ìƒˆ í´ë”ë¥¼ ë§Œë“­ë‹ˆë‹¤.
save_dir = Path('checkpoints') / datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S_resume')
save_dir.mkdir(parents=True)

# â­â­â­ 3. ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ìê°€ ì œê³µí•œ ê²½ë¡œ) â­â­â­
# ì´ íŒŒì¼ì—ì„œ ê°€ì¤‘ì¹˜(Weights)ì™€ íƒí—˜ë¥ (Epsilon)ì„ ë³µêµ¬í•©ë‹ˆë‹¤.
checkpoint_path = Path("/home/jwg/MadMario/checkpoints/2025-12-07T11-26-29/mario_net_2.chkpt")

print(f"ğŸ”„ í•™ìŠµ ì´ì–´í•˜ê¸° ëª¨ë“œ ì‹œì‘...")
print(f"ğŸ“‚ ë¡œë“œí•  ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")

# 4. ë§ˆë¦¬ì˜¤ ì—ì´ì „íŠ¸ ìƒì„± (ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ)
mario = Mario(
    state_dim=(4, 84, 84), 
    action_dim=env.action_space.n,
    save_dir=save_dir,
    checkpoint=checkpoint_path  # ğŸ‘ˆ ì—¬ê¸°ì— ê²½ë¡œë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤!
)

# â­â­â­ 5. Burn-in ì œê±° (í•µì‹¬!) â­â­â­
# ì´ë¯¸ ë˜‘ë˜‘í•œ ëª¨ë¸ì´ë¯€ë¡œ 10ë§Œ ìŠ¤í…ì„ ê¸°ë‹¤ë¦´ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
# ë²„í¼ì— ë°°ì¹˜ ì‚¬ì´ì¦ˆ(32ê°œ)ë§Œ ì°¨ë©´ ë°”ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.
mario.burnin = 0  
print(f"ğŸ”¥ Burn-in ê°•ì œ í•´ì œ: 0 (ì¦‰ì‹œ í•™ìŠµ ì‹œì‘)")
print(f"ğŸ“Š í˜„ì¬ íƒí—˜ë¥ (Epsilon): {mario.exploration_rate:.4f}")

logger = MetricLogger(save_dir)

# 6. ì¶”ê°€ í•™ìŠµ ëª©í‘œ ì„¤ì •
# ì´ë¯¸ ë§ì´ í•™ìŠµí–ˆìœ¼ë¯€ë¡œ í•„ìš”í•œ ë§Œí¼ ì¶”ê°€ë¡œ ëŒë¦½ë‹ˆë‹¤.
episodes = 20000 

print(f"\nğŸ¯ ì¶”ê°€ í•™ìŠµ ëª©í‘œ: {episodes:,} ì—í”¼ì†Œë“œ")
print("-" * 80)

# 7. í•™ìŠµ ë£¨í”„ (ê¸°ì¡´ê³¼ ë™ì¼)
for e in range(episodes):
    state = env.reset()
    
    while True:
        action = mario.act(state)
        next_state, reward, done, info = env.step(action)
        
        mario.cache(state, next_state, action, reward, done)
        
        # burninì„ 0ìœ¼ë¡œ í–ˆê¸° ë•Œë¬¸ì—, ë©”ëª¨ë¦¬ê°€ 32ê°œ ì°¨ëŠ” ìˆœê°„ë¶€í„° ë°”ë¡œ learn()ì´ ì‘ë™í•©ë‹ˆë‹¤.
        q, loss = mario.learn()
        
        logger.log_step(reward, loss, q)
        state = next_state
        
        if done or info['flag_get']:
            break
    
    logger.log_episode()
    mario.episode_finished()
    
    if e % 20 == 0:
        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)

env.close()
print(f"\nâœ… {episodes:,} ì—í”¼ì†Œë“œ ì¶”ê°€ í•™ìŠµ ì™„ë£Œ!")